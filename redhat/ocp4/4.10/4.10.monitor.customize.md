# openshift 4.10 监控模块自定义，监控用户项目，自定义看板

红帽openshift4里面的监控体系是prometheus + grafana，自然就是可以扩展，对用户的应用进行监控的，[官方也有相应的文档](https://docs.openshift.com/container-platform/4.10/monitoring/configuring-the-monitoring-stack.html)，只不过官方并不推荐用openshift4自带的prometheus去监控客户的应用，因为本来系统的监控就已经很消耗资源了，再多用户的监控，会吃不消。

所以文本的做法，只能用在PoC，或者小集群上。

# 给监控添加存储 并 激活用户空间监控

```bash

# oc new-project openshift-user-workload-monitoring

cat << EOF > /data/install/monitor.cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    enableUserWorkload: true
    prometheusK8s: 
      retention: 7d
      nodeSelector:
        deploy-acm: "true"
      volumeClaimTemplate:
       spec:
         storageClassName: nfs-storage-provisioner
         volumeMode: Filesystem
         resources:
           requests:
             storage: 10Gi
    prometheusOperator:
      nodeSelector:
        deploy-acm: "true"
    alertmanagerMain:
      nodeSelector:
        deploy-acm: "true"
      volumeClaimTemplate:
        spec:
          storageClassName: nfs-storage-provisioner
          resources:
            requests:
              storage: 10Gi        
    kubeStateMetrics:
      nodeSelector:
        deploy-acm: "true"
    grafana:
      nodeSelector:
        deploy-acm: "true"
    telemeterClient:
      nodeSelector:
        deploy-acm: "true"
    k8sPrometheusAdapter:
      nodeSelector:
        deploy-acm: "true"
    openshiftStateMetrics:
      nodeSelector:
        deploy-acm: "true"
    thanosQuerier:
      nodeSelector:
        deploy-acm: "true"
EOF

oc apply -f /data/install/monitor.cm.yaml

oc -n openshift-user-workload-monitoring get pod
# NAME                                   READY   STATUS    RESTARTS   AGE
# prometheus-operator-8474d65649-w6gqw   2/2     Running   0          72s
# prometheus-user-workload-0             5/5     Running   0          68s
# prometheus-user-workload-1             5/5     Running   0          68s
# thanos-ruler-user-workload-0           3/3     Running   0          65s
# thanos-ruler-user-workload-1           3/3     Running   0          65s


cat << EOF > /data/install/monitor.cm.user.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: user-workload-monitoring-config
  namespace: openshift-user-workload-monitoring
data:
  config.yaml: |
    prometheusOperator:
      nodeSelector:
        deploy-acm: "true"
    prometheus:
      retention: 7d
      nodeSelector:
        deploy-acm: "true"
      volumeClaimTemplate:
        spec:
          storageClassName: nfs-storage-provisioner
          resources:
            requests:
              storage: 10Gi        
    thanosRuler:
      nodeSelector:
        deploy-acm: "true"
      volumeClaimTemplate:
        spec:
          storageClassName: nfs-storage-provisioner
          resources:
            requests:
              storage: 10Gi
EOF

oc apply -f /data/install/monitor.cm.user.yaml

```

# 部署一个演示应用 并 监控

```bash
# on vultr, prepare image
podman pull ghcr.io/rhobs/prometheus-example-app:0.4.1
podman tag ghcr.io/rhobs/prometheus-example-app:0.4.1 quay.io/wangzheng422/qimgs:rhobs-prometheus-example-app-0.4.1
podman push quay.io/wangzheng422/qimgs:rhobs-prometheus-example-app-0.4.1

cat << EOF > /data/install/monitor.cm.dep.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prometheus-example-app
  name: prometheus-example-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus-example-app
  template:
    metadata:
      labels:
        app: prometheus-example-app
    spec:
      containers:
      - image: quay.io/wangzheng422/qimgs:rhobs-prometheus-example-app-0.4.1
        imagePullPolicy: IfNotPresent
        name: prometheus-example-app
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus-example-app
  name: prometheus-example-app
spec:
  ports:
  - port: 8080
    protocol: TCP
    targetPort: 8080
    name: web
  selector:
    app: prometheus-example-app
  type: ClusterIP
EOF
oc create -n demo -f /data/install/monitor.cm.dep.yaml

cat << EOF > /data/install/monitor.cm.mon.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    k8s-app: prometheus-example-monitor
  name: prometheus-example-monitor
spec:
  endpoints:
  - interval: 30s
    port: web
    scheme: http
  selector:
    matchLabels:
      app: prometheus-example-app
EOF
oc create -n demo -f /data/install/monitor.cm.mon.yaml

```
在界面上定义一个查询，就可以看到指标了
```
rate( http_requests_total{ job="prometheus-example-app"  }[1m])
```

# 定制看板 / grafana

我们从operator hub里面部署一个grafana。然后按照[官方的知识库](https://access.redhat.com/solutions/5335491)进行配置。

```bash
# https://access.redhat.com/solutions/5335491

oc get route -n openshift-monitoring
# NAME                HOST/PORT                                                     PATH   SERVICES            PORT    TERMINATION          WILDCARD
# alertmanager-main   alertmanager-main-openshift-monitoring.apps.ocp4.redhat.ren   /api   alertmanager-main   web     reencrypt/Redirect   None
# grafana             grafana-openshift-monitoring.apps.ocp4.redhat.ren                    grafana             https   reencrypt/Redirect   None
# prometheus-k8s      prometheus-k8s-openshift-monitoring.apps.ocp4.redhat.ren             prometheus-k8s      web     reencrypt/Redirect   None
# thanos-querier      thanos-querier-openshift-monitoring.apps.ocp4.redhat.ren      /api   thanos-querier      web     reencrypt/Redirect   None

VAR_URL="https://thanos-querier-openshift-monitoring.apps.ocp4.redhat.ren"

oc project openshift-user-workload-monitoring
oc adm policy add-cluster-role-to-user cluster-monitoring-view -z grafana-serviceaccount

oc serviceaccounts get-token grafana-serviceaccount

VAR_TOKEN=`oc serviceaccounts get-token grafana-serviceaccount`

cat << EOF > /data/install/monitor.cm.grafana.yaml
apiVersion: integreatly.org/v1alpha1
kind: GrafanaDataSource
metadata:
  name: prometheus-grafanadatasource
  namespace: openshift-user-workload-monitoring
spec:
  datasources:
  - access: proxy
    editable: true
    isDefault: true
    jsonData:
      httpHeaderName1: 'Authorization'
      timeInterval: 5s
      tlsSkipVerify: true
    name: Prometheus
    secureJsonData:
      httpHeaderValue1: 'Bearer $VAR_TOKEN'
    type: prometheus
    url: '$VAR_URL'
  name: prometheus-grafanadatasource.yaml
EOF

oc project openshift-user-workload-monitoring
oc create -f /data/install/monitor.cm.grafana.yaml


```
