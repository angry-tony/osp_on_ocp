# LLM on openshift

continue with [install doc](./4.13.single.node.upi.agent.md)

we have 2 node, 1 master, 1 worker.

# gpu operator

- https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/introduction.html#openshift-introduction

Installing the Node Feature Discovery (NFD) Operator

![](imgs/2023-10-13-20-48-28.png)

install gpu operator through opeartor hub

![](imgs/2023-10-13-20-33-26.png)


# build base container image

```bash

# on vultr
mkdir -p /data/nv
cd /data/nv

cat << 'EOF' > nv.Dockerfile
FROM registry.access.redhat.com/ubi9/ubi:9.2

RUN dnf repolist && \
    sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf && \
    sed -i 's|$releasever|9.2|g' /etc/yum.repos.d/redhat.repo && \
    sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo && \
    dnf -y update && \
    dnf install -y --allowerasing coreutils && \
    dnf groupinstall -y --allowerasing development server && \
    dnf clean all

RUN dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm && \
    dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo && \
    `#dnf -y module install nvidia-driver:latest-dkms &&` \
    dnf -y install --allowerasing cuda && \
    dnf install -y --allowerasing libnccl libnccl-devel libnccl-static && \
    dnf install -y --allowerasing conda python3.11 && \
    dnf clean all

RUN dnf install -y rsync lftp && \
    dnf clean all

EOF

podman build --squash -t quay.io/wangzheng422/qimgs:gpu-nv-base-rhel92-v01 -f nv.Dockerfile ./

podman push quay.io/wangzheng422/qimgs:gpu-nv-base-rhel92-v01

podman save quay.io/wangzheng422/qimgs:gpu-nv-base-rhel92-v01 | pigz -c > gpu-nv-base.tgz

python -m http.server 15443

# back to helper node
# copy back the base image
oc image mirror quay.io/wangzheng422/qimgs:gpu-nv-base-rhel92-v01 quaylab.infra.wzhlab.top:5443/wangzheng422/qimgs:gpu-nv-base-rhel92-v01

podman load -i gpu-nv-base.tgz

podman image tag quay.io/wangzheng422/qimgs:gpu-nv-base-rhel92-v01 quaylab.infra.wzhlab.top:5443/wangzheng422/qimgs:gpu-nv-base-rhel92-v01

podman push quaylab.infra.wzhlab.top:5443/wangzheng422/qimgs:gpu-nv-base-rhel92-v01

```

# llm with a single pod

```bash
# create some static host path to use
# go to worker-01-demo
# 01,02,03,04,05,06,07,08,09,10
for i in $(seq -w 1 10); do
  mkdir -p "/var/wzh-local-pv/static/$i"
done
mkdir -p /var/wzh-local-pv/dynamic
chcon -Rt container_file_t /var/wzh-local-pv/

# on helper
cat << EOF > ${BASE_DIR}/data/install/local-pv.yaml
---
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: local-volume
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-pv-01
spec:
  capacity:
    storage: 4500Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-volume
  local:
    path: /var/wzh-local-pv/static/01
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - worker-01-demo
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: local-pvc-demo
spec:
  accessModes:
  - ReadWriteOnce
  volumeMode: Filesystem 
  resources:
    requests:
      storage: 4500Gi 
  storageClassName: local-volume
EOF
oc create --save-config -f ${BASE_DIR}/data/install/local-pv.yaml

# oc delete -f ${BASE_DIR}/data/install/local-pv.yaml


# https://master.sdk.operatorframework.io/docs/best-practices/pod-security-standards/
oc create ns llm-demo
oc label --overwrite ns llm-demo \
   pod-security.kubernetes.io/enforce=privileged


cat << EOF > ${BASE_DIR}/data/install/pod.yaml
---
kind: Pod
apiVersion: v1
metadata:
  annotations:
    openshift.io/scc: privileged
  name: demo1
spec:
  nodeSelector:
    kubernetes.io/hostname: worker-01-demo
  restartPolicy: Always
  containers:
    - name: demo1
      image: >- 
        docker.io/nvidia/cuda:12.2.2-devel-ubi9
      # quaylab.infra.wzhlab.top:5443/wangzheng422/qimgs:gpu-nv-base-rhel92-v01
      securityContext:
        # privileged: true
        AllowPrivilegedContainer: true
      env:
        - name: key
          value: value
      command: 
        - sleep
        - infinity
      volumeMounts:
        - mountPath: /data
          name: demo 
          readOnly: false
      resources:
        limits:
          nvidia.com/gpu: 2
  volumes:
    - name: demo 
      persistentVolumeClaim:
        claimName: local-pvc-demo 
EOF

oc create --save-config -n llm-demo -f ${BASE_DIR}/data/install/pod.yaml

# oc delete -n llm-demo -f ${BASE_DIR}/data/install/pod.yaml

```